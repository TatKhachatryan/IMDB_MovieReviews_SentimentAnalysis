{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b21745-66cf-47b3-975a-cf939a436711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data prep\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"wordnet\")\n",
    "\n",
    "# model training\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b900e90-8b84-46f0-9826-32723a57db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1592ea6-f98b-45dd-9505-cae55ed542d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5f23a6-acb8-44e9-9dff-1c1474b0cbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1856e491-95e0-4aca-97ab-6b3ac81e0b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of sentiment class\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1528ac5-a863-4ab6-af8a-e40285c08846",
   "metadata": {},
   "source": [
    "## Basic Text Statistics (Word Count & Sentence Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85a124a-4a89-4689-9c5c-5184a74569ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Text Statistics:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>231.156940</td>\n",
       "      <td>1309.431020</td>\n",
       "      <td>14.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.343997</td>\n",
       "      <td>989.728014</td>\n",
       "      <td>9.890968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>970.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>280.000000</td>\n",
       "      <td>1590.250000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2470.000000</td>\n",
       "      <td>13704.000000</td>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_count    char_count  sentence_count\n",
       "count  50000.000000  50000.000000    50000.000000\n",
       "mean     231.156940   1309.431020       14.010400\n",
       "std      171.343997    989.728014        9.890968\n",
       "min        4.000000     32.000000        1.000000\n",
       "25%      126.000000    699.000000        8.000000\n",
       "50%      173.000000    970.000000       11.000000\n",
       "75%      280.000000   1590.250000       17.000000\n",
       "max     2470.000000  13704.000000      176.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"word_count\"] = df[\"review\"].apply(lambda x: len(str(x).split()))\n",
    "df[\"char_count\"] = df[\"review\"].apply(lambda x: len(str(x)))\n",
    "df[\"sentence_count\"] = df[\"review\"].apply(lambda x: len(str(x).split(\".\")))\n",
    "\n",
    "print(\"Basic Text Statistics:\\n\")\n",
    "df[[\"word_count\", \"char_count\", \"sentence_count\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0e3660-3f58-4152-bc8b-95692c22e335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in dataset: 11557847\n"
     ]
    }
   ],
   "source": [
    "total_words = df[\"word_count\"].sum()\n",
    "print(f\"Total words in dataset: {total_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b625a-b0da-44d7-8f18-e6b994294b8b",
   "metadata": {},
   "source": [
    "## \"review\" column preprocessing pipeline\n",
    "this process will include:\n",
    "* Converting to lowercase\n",
    "* Removing special characters, punctuation, and numbers\n",
    "* Tokenizing\n",
    "* Removing stopwords\n",
    "* Lemmatizing\n",
    "\n",
    "P.S. Tokenizing means breaking text into smaller parts, usually words or sentences, to make it easier to analyze. <br>Lemmatizing reduces words to their base or dictionary form (e.g., running â†’ run), helping models understand different variations of the same word. Both techniques improve text processing by making data cleaner and more structured for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60114d28-5c68-48d8-923a-1129e1351c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_text(text):\n",
    "    # removing HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    return text\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f0fa9f-0284-422d-bafc-3639d85cdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining stopwords, lemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# cleaning function\n",
    "def preprocess_text(text):\n",
    "    # converting to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # removing special characters, numbers, and punctuation\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    \n",
    "    # tokenizing the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # removing stopwords and apply lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # joining tokens back into a string\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85ea0df1-13fd-4324-86da-135788633ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. The filming tec...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  one reviewer mentioned watching oz episode you...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "df[[\"review\", \"cleaned_review\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db92a7f-b935-400a-9da3-951d0acd048e",
   "metadata": {},
   "source": [
    "### Check the prep results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055cdbc9-3e38-421c-a249-f8648a72e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_length</th>\n",
       "      <th>cleaned_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1285.190240</td>\n",
       "      <td>819.542460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>971.155366</td>\n",
       "      <td>632.153317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>689.000000</td>\n",
       "      <td>429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>953.000000</td>\n",
       "      <td>603.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1559.000000</td>\n",
       "      <td>998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13584.000000</td>\n",
       "      <td>9182.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_length  cleaned_length\n",
       "count     50000.000000    50000.000000\n",
       "mean       1285.190240      819.542460\n",
       "std         971.155366      632.153317\n",
       "min          32.000000       17.000000\n",
       "25%         689.000000      429.000000\n",
       "50%         953.000000      603.000000\n",
       "75%        1559.000000      998.000000\n",
       "max       13584.000000     9182.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"original_length\"] = df[\"review\"].apply(len)\n",
    "df[\"cleaned_length\"] = df[\"cleaned_review\"].apply(len)\n",
    "\n",
    "# length statistics comparison\n",
    "df[[\"original_length\", \"cleaned_length\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d90863-dd46-47b4-a4c5-8627779a0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# getting most common words in original and cleaned text\n",
    "original_words = Counter(\" \".join(df[\"review\"]).split()).most_common(20)\n",
    "cleaned_words = Counter(\" \".join(df[\"cleaned_review\"]).split()).most_common(20)\n",
    "\n",
    "print(\"Top 20 words in Original Reviews:\\n\", original_words)\n",
    "print(\"\\nTop 20 words in Cleaned Reviews:\\n\", cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779175aa-f8e6-443e-a095-fc27fe8962bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud_original = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(df[\"review\"]))\n",
    "wordcloud_cleaned = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(df[\"cleaned_review\"]))\n",
    "\n",
    "# plotting side-by-side comparison\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "ax[0].imshow(wordcloud_original, interpolation=\"bilinear\")\n",
    "ax[0].set_title(\"Original Reviews Word Cloud\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(wordcloud_cleaned, interpolation=\"bilinear\")\n",
    "ax[1].set_title(\"Cleaned Reviews Word Cloud\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2fb11-b858-41de-a103-5d8c617f7ff8",
   "metadata": {},
   "source": [
    "## Train a Model\n",
    "Simple Naive Bayes / Logistic Regression Model\n",
    "\n",
    "We use Naive Bayes because it's a simple, fast, and effective algorithm for text classification, especially when features (words) are independent, which is often assumed in NLP tasks. Logistic Regression is used because it's a strong baseline model for binary classification (positive vs. negative), performs well with high-dimensional text data, and outputs interpretable probabilities. Both models work well with small to medium-sized datasets and are computationally efficient compared to deep learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd7c435-a8ed-4b4e-8fdd-2cc91d9a707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting sentiment to binary (0: Negative, 1: Positive)\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"review\"], df[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "# This removes common English stopwords and keeps only the top 5,000 most important words from the dataset. \n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "\n",
    "# This learns the vocabulary from X_train and transforms it into a matrix where each row represents a review as a set of weighted word features.\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# This transforms X_test using the same learned vocabulary from X_train, ensuring consistency between train and test data.\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9efb180-4b2d-4498-af67-e3be56aef7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying that the vectorizer has learned something from the training data\n",
    "# print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f476912-c437-42cd-9d81-b0e3299d4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "nb_preds = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_preds = lr_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ddcc1-75eb-4617-a7c5-6fa4008285b9",
   "metadata": {},
   "source": [
    "Even if we already removed stopwords using NLTK, TF-IDF is still useful for several reasons:\n",
    "\n",
    "* **Weighting Important Words** â€“ TF-IDF assigns higher importance to words that appear frequently in a document but not in all documents, making it better at distinguishing meaningful terms.\n",
    "\n",
    "* **Handling Word Frequency Differences** â€“ Some words (even after stopword removal) appear very frequently but might not be important. TF-IDF helps reduce their impact by giving lower weights to overly common words.\n",
    "\n",
    "* **Feature Representation for ML Models** â€“ Machine learning models can't work with raw text, so we need numerical features. TF-IDF converts text into a sparse matrix of weighted word frequencies, which is more informative than simple word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527a7c9-ec13-4341-ae9e-f49c2ad97960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "print(\"Naive Bayes:\")\n",
    "print(classification_report(y_test, nb_preds))\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(classification_report(y_test, lr_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
