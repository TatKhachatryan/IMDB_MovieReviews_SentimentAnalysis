{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b21745-66cf-47b3-975a-cf939a436711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data prep\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"wordnet\")\n",
    "\n",
    "# model training\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b900e90-8b84-46f0-9826-32723a57db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1592ea6-f98b-45dd-9505-cae55ed542d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5f23a6-acb8-44e9-9dff-1c1474b0cbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1856e491-95e0-4aca-97ab-6b3ac81e0b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of sentiment class\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1528ac5-a863-4ab6-af8a-e40285c08846",
   "metadata": {},
   "source": [
    "## Basic Text Statistics (Word Count & Sentence Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85a124a-4a89-4689-9c5c-5184a74569ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Text Statistics:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>231.156940</td>\n",
       "      <td>1309.431020</td>\n",
       "      <td>14.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.343997</td>\n",
       "      <td>989.728014</td>\n",
       "      <td>9.890968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>970.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>280.000000</td>\n",
       "      <td>1590.250000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2470.000000</td>\n",
       "      <td>13704.000000</td>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_count    char_count  sentence_count\n",
       "count  50000.000000  50000.000000    50000.000000\n",
       "mean     231.156940   1309.431020       14.010400\n",
       "std      171.343997    989.728014        9.890968\n",
       "min        4.000000     32.000000        1.000000\n",
       "25%      126.000000    699.000000        8.000000\n",
       "50%      173.000000    970.000000       11.000000\n",
       "75%      280.000000   1590.250000       17.000000\n",
       "max     2470.000000  13704.000000      176.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"word_count\"] = df[\"review\"].apply(lambda x: len(str(x).split()))\n",
    "df[\"char_count\"] = df[\"review\"].apply(lambda x: len(str(x)))\n",
    "df[\"sentence_count\"] = df[\"review\"].apply(lambda x: len(str(x).split(\".\")))\n",
    "\n",
    "print(\"Basic Text Statistics:\\n\")\n",
    "df[[\"word_count\", \"char_count\", \"sentence_count\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0e3660-3f58-4152-bc8b-95692c22e335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in dataset: 11557847\n"
     ]
    }
   ],
   "source": [
    "total_words = df[\"word_count\"].sum()\n",
    "print(f\"Total words in dataset: {total_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b625a-b0da-44d7-8f18-e6b994294b8b",
   "metadata": {},
   "source": [
    "## \"review\" column preprocessing pipeline\n",
    "this process will include:\n",
    "* Converting to lowercase\n",
    "* Removing special characters, punctuation, and numbers\n",
    "* Tokenizing\n",
    "* Removing stopwords\n",
    "* Lemmatizing\n",
    "\n",
    "P.S. Tokenizing means breaking text into smaller parts, usually words or sentences, to make it easier to analyze. <br>Lemmatizing reduces words to their base or dictionary form (e.g., running → run), helping models understand different variations of the same word. Both techniques improve text processing by making data cleaner and more structured for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60114d28-5c68-48d8-923a-1129e1351c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_text(text):\n",
    "    # removing HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    return text\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f0fa9f-0284-422d-bafc-3639d85cdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining stopwords, lemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# cleaning function\n",
    "def preprocess_text(text):\n",
    "    # converting to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # removing special characters, numbers, and punctuation\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    \n",
    "    # tokenizing the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # removing stopwords and apply lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # joining tokens back into a string\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85ea0df1-13fd-4324-86da-135788633ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. The filming tec...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  one reviewer mentioned watching oz episode you...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "df[[\"review\", \"cleaned_review\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db92a7f-b935-400a-9da3-951d0acd048e",
   "metadata": {},
   "source": [
    "### Check the prep results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055cdbc9-3e38-421c-a249-f8648a72e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_length</th>\n",
       "      <th>cleaned_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1285.190240</td>\n",
       "      <td>819.542460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>971.155366</td>\n",
       "      <td>632.153317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>689.000000</td>\n",
       "      <td>429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>953.000000</td>\n",
       "      <td>603.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1559.000000</td>\n",
       "      <td>998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13584.000000</td>\n",
       "      <td>9182.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_length  cleaned_length\n",
       "count     50000.000000    50000.000000\n",
       "mean       1285.190240      819.542460\n",
       "std         971.155366      632.153317\n",
       "min          32.000000       17.000000\n",
       "25%         689.000000      429.000000\n",
       "50%         953.000000      603.000000\n",
       "75%        1559.000000      998.000000\n",
       "max       13584.000000     9182.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"original_length\"] = df[\"review\"].apply(len)\n",
    "df[\"cleaned_length\"] = df[\"cleaned_review\"].apply(len)\n",
    "\n",
    "# length statistics comparison\n",
    "df[[\"original_length\", \"cleaned_length\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d90863-dd46-47b4-a4c5-8627779a0fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words in Original Reviews:\n",
      " [('the', 568758), ('a', 306961), ('and', 301931), ('of', 283626), ('to', 261851), ('is', 203056), ('in', 169983), ('I', 133367), ('that', 126818), ('this', 113733), ('it', 107920), ('was', 92658), ('as', 83132), ('with', 82569), ('for', 80920), ('The', 68906), ('but', 66286), ('on', 61197), ('movie', 60762), ('are', 56513)]\n",
      "\n",
      "Top 20 words in Cleaned Reviews:\n",
      " [('movie', 99026), ('film', 89809), ('one', 52677), ('like', 39790), ('time', 29397), ('good', 28615), ('character', 27573), ('get', 24435), ('even', 24286), ('story', 24229), ('would', 24001), ('make', 23565), ('see', 23494), ('really', 22900), ('scene', 20706), ('much', 18897), ('well', 18629), ('people', 17979), ('great', 17803), ('bad', 17673)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# getting most common words in original and cleaned text\n",
    "original_words = Counter(\" \".join(df[\"review\"]).split()).most_common(20)\n",
    "cleaned_words = Counter(\" \".join(df[\"cleaned_review\"]).split()).most_common(20)\n",
    "\n",
    "print(\"Top 20 words in Original Reviews:\\n\", original_words)\n",
    "print(\"\\nTop 20 words in Cleaned Reviews:\\n\", cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "779175aa-f8e6-443e-a095-fc27fe8962bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# wordcloud_original = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(df[\"review\"]))\n",
    "# wordcloud_cleaned = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(df[\"cleaned_review\"]))\n",
    "\n",
    "# # plotting side-by-side comparison\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# ax[0].imshow(wordcloud_original, interpolation=\"bilinear\")\n",
    "# ax[0].set_title(\"Original Reviews Word Cloud\")\n",
    "# ax[0].axis(\"off\")\n",
    "\n",
    "# ax[1].imshow(wordcloud_cleaned, interpolation=\"bilinear\")\n",
    "# ax[1].set_title(\"Cleaned Reviews Word Cloud\")\n",
    "# ax[1].axis(\"off\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2fb11-b858-41de-a103-5d8c617f7ff8",
   "metadata": {},
   "source": [
    "## Train a Model\n",
    "Simple Naive Bayes / Logistic Regression Model\n",
    "\n",
    "We use Naive Bayes because it's a simple, fast, and effective algorithm for text classification, especially when features (words) are independent, which is often assumed in NLP tasks. Logistic Regression is used because it's a strong baseline model for binary classification (positive vs. negative), performs well with high-dimensional text data, and outputs interpretable probabilities. Both models work well with small to medium-sized datasets and are computationally efficient compared to deep learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acd7c435-a8ed-4b4e-8fdd-2cc91d9a707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import pipeline\n",
    "\n",
    "# ✅ Convert sentiment labels to binary (0: Negative, 1: Positive)\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
    "\n",
    "# ✅ Split data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"review\"], df[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ TF-IDF vectorization (removes stopwords & keeps top 5,000 words)\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)  # Learn vocabulary & transform train data\n",
    "X_test_tfidf = vectorizer.transform(X_test)  # Transform test data using same vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9efb180-4b2d-4498-af67-e3be56aef7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying that the vectorizer has learned something from the training data\n",
    "# print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ddcc1-75eb-4617-a7c5-6fa4008285b9",
   "metadata": {},
   "source": [
    "Even if we already removed stopwords using NLTK, TF-IDF is still useful for several reasons:\n",
    "\n",
    "* **Weighting Important Words** – TF-IDF assigns higher importance to words that appear frequently in a document but not in all documents, making it better at distinguishing meaningful terms.\n",
    "\n",
    "* **Handling Word Frequency Differences** – Some words (even after stopword removal) appear very frequently but might not be important. TF-IDF helps reduce their impact by giving lower weights to overly common words.\n",
    "\n",
    "* **Feature Representation for ML Models** – Machine learning models can't work with raw text, so we need numerical features. TF-IDF converts text into a sparse matrix of weighted word frequencies, which is more informative than simple word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4833072-71f5-453c-9a69-ab4284b0b495",
   "metadata": {},
   "source": [
    "## End-to-End Model Training, Evaluation & Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f476912-c437-42cd-9d81-b0e3299d4d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Runtime (min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes (5K)</td>\n",
       "      <td>0.8548</td>\n",
       "      <td>0.857654</td>\n",
       "      <td>0.854257</td>\n",
       "      <td>0.855952</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression (5K)</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>0.876336</td>\n",
       "      <td>0.909307</td>\n",
       "      <td>0.892517</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DistilBERT (5K)</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>0.909167</td>\n",
       "      <td>0.860198</td>\n",
       "      <td>0.884005</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0          Naive Bayes (5K)    0.8548   0.857654  0.854257  0.855952   \n",
       "1  Logistic Regression (5K)    0.8894   0.876336  0.909307  0.892517   \n",
       "2           DistilBERT (5K)    0.8860   0.909167  0.860198  0.884005   \n",
       "\n",
       "   Runtime (min)  \n",
       "0           0.01  \n",
       "1           0.02  \n",
       "2          49.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to evaluate model performance and measure runtime\n",
    "def evaluate_model_with_time(model_name, y_true, y_pred, start_time):\n",
    "    end_time = time.time()\n",
    "    runtime_minutes = (end_time - start_time) / 60  # Convert to minutes\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1-Score\": f1_score(y_true, y_pred),\n",
    "        \"Runtime (min)\": round(runtime_minutes, 2)\n",
    "    }\n",
    "\n",
    "# selecting a random 3,000-sample test subset for fair comparison\n",
    "sample_indices = np.random.choice(len(X_test), 5000, replace=False)\n",
    "X_test_sample = [X_test.iloc[i] for i in sample_indices]\n",
    "y_test_sample = [y_test.iloc[i] for i in sample_indices]\n",
    "\n",
    "# training & evaluating Naive Bayes ###\n",
    "nb_model = MultinomialNB()\n",
    "start_time = time.time()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "nb_preds_sample = nb_model.predict(vectorizer.transform(X_test_sample))\n",
    "nb_results_sample = evaluate_model_with_time(\"Naive Bayes (5K)\", y_test_sample, nb_preds_sample, start_time)\n",
    "\n",
    "# training & evaluating Logistic Regression ###\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "start_time = time.time()\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_preds_sample = lr_model.predict(vectorizer.transform(X_test_sample))\n",
    "lr_results_sample = evaluate_model_with_time(\"Logistic Regression (5K)\", y_test_sample, lr_preds_sample, start_time)\n",
    "\n",
    "# loading & evaluating DistilBERT ###\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    tokenizer=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    truncation=True\n",
    ")\n",
    "start_time = time.time()\n",
    "bert_preds_sample = classifier(X_test_sample)\n",
    "bert_preds_binary_sample = [1 if pred['label'] == 'POSITIVE' else 0 for pred in bert_preds_sample]\n",
    "bert_results_sample = evaluate_model_with_time(\"DistilBERT (5K)\", y_test_sample, bert_preds_binary_sample, start_time)\n",
    "\n",
    "df_results_sample = pd.DataFrame([nb_results_sample, lr_results_sample, bert_results_sample])\n",
    "df_results_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d86946-9026-4445-bdff-c02e1f3e2210",
   "metadata": {},
   "source": [
    "1. Naive Bayes (5K)\n",
    "* **Accuracy**: 0.8548: This is a solid performance, indicating that Naive Bayes is performing reasonably well with 5,000 reviews.\n",
    "* **Precision**: 0.8577: Precision is slightly better than recall, meaning that when Naive Bayes predicts a review as positive, it's fairly accurate.\n",
    "* **Recall**: 0.8543: Recall is very close to precision, which means the model is catching most of the positive reviews (though not all).\n",
    "* **F1-Score**: 0.8560: This is quite a good F1 score, balancing precision and recall well.\n",
    "* **Runtime**: 0.01 minutes: Fast! Naive Bayes is very efficient, even with 5,000 reviews.\n",
    "2. Logistic Regression (5K)\n",
    "* **Accuracy**: 0.8894: Logistic Regression continues to show strong performance, with an accuracy of 88.94%, a bit higher than Naive Bayes.\n",
    "* **Precision**: 0.8763: Precision is slightly lower than Naive Bayes, meaning there are slightly more false positives.\n",
    "* **Recall**: 0.9093: Recall is better than Naive Bayes, meaning Logistic Regression is good at identifying positive reviews.\n",
    "* **F1-Score**: 0.8925: The higher F1 score suggests that Logistic Regression balances precision and recall better than Naive Bayes.\n",
    "* **Runtime**: 0.02 minutes: Still quick and efficient for 5,000 samples, but it does take a bit longer than Naive Bayes.\n",
    "3. DistilBERT (5K)\n",
    "* **Accuracy**: 0.8860: DistilBERT's accuracy is competitive with Logistic Regression, but lower than its performance on the 1K sample.\n",
    "* **Precision**: 0.9092: DistilBERT achieves the highest precision, meaning it's very good at predicting positive reviews when it does make that prediction.\n",
    "* **Recall**: 0.8602: The recall is lower than its precision, meaning it's not catching as many of the actual positive reviews, which could lead to more false negatives.\n",
    "* **F1-Score**: 0.8840: A decent F1 score, though not the best among the models, showing that its precision is pulling the overall performance up.\n",
    "* **Runtime**: 49.00 minutes: As expected, the runtime is significantly longer. DistilBERT benefits from a powerful transformer model but is much slower compared to the traditional machine learning models.\n",
    "\n",
    "**Comparison and Key Takeaways:**\n",
    "Naive Bayes is still the fastest but performs slightly worse in accuracy and other metrics compared to Logistic Regression.\n",
    "Logistic Regression shows a strong balance of precision, recall, and F1-score, making it a reliable choice for this task.\n",
    "DistilBERT, while being competitive in terms of precision, still lags behind in recall and has a significantly longer runtime. It could be more effective with fine-tuning, but for now, it's slower than the other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
